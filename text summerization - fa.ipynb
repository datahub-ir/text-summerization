{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install lxml\n",
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install lxml \n",
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import heapq\n",
    "from urllib.parse import quote\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettings the data source\n",
    "source = urllib.request.urlopen('https://fa.wikipedia.org/wiki/'+ quote('گرمایش_جهانی')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the data/ creating BeautifulSoup object\n",
    "soup = bs.BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the data\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "#     text += paragraph.text\n",
    "    text += normalizer.normalize(paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "# در اتمسفر زمین را تجربه نکرده‌است.[۲۴]\n",
    "text = re.sub(r'\\[[۰-۹]*\\]',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "# clean_text = re.sub(r'\\W',' ',clean_text)\n",
    "# clean_text = re.sub(r'\\d',' ',clean_text)\n",
    "# clean_text = re.sub(r'\\s+',' ',clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword list\n",
    "stopwords = []\n",
    "file = open('Mojiry - PersianStopWords.txt').read()\n",
    "[stopwords.append(x) for x in file.split()]\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts \n",
    "word2count = {}\n",
    "for word in word_tokenize(text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting counts to weights\n",
    "max_count = max(word2count.values())\n",
    "for key in word2count.keys():\n",
    "    word2count[key] = word2count[key]/max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product sentence scores    \n",
    "sent2score = {}\n",
    "for sentence in sentences:\n",
    "    for word in word_tokenize(sentence.lower()):\n",
    "        if word in word2count.keys():\n",
    "            if len(sentence.split(' ')) < 25:#جملات طولانی در خلاصه سازی مفید نیستند، برای خلاصه سازی دنبال جملات با کمترین تعداد کلمه هستیم\n",
    "                if sentence not in sent2score.keys():\n",
    "                    sent2score[sentence] = word2count[word]\n",
    "                else:\n",
    "                    sent2score[sentence] += word2count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "براساس گزارش سازمان جهانی هواشناسی، سال ۲۰۱۶ گرم‌ترین سال زمین بوده‌است، و انتظار می‌رود این گرما در سال ۲۰۱۷ نیز کماکان ادامه داشته باشد.\n",
      "استناد این دانشمندان برای گفته‌های خویش، وقوع دوره‌های سرد و گرم در طول مدت زمانی است که از عمر زمین می‌گذرد.\n",
      "همچنین ببینید: تأثیرات گرم‌شدن زمین برخی از دانشمندان، افزایش توفان‌ها و گردبادهای سهمگین را یکی از نتایج گرم شدن کره زمین قلمداد می‌کنند.\n",
      "وقتی این اتفاق در مقیاس بزرگ رخ دهد، مانند این است که زمین را با یک پتو پوشانده‌ایم.\n",
      "اما در طول تاریخ مسکونی شدن زمین این اولین باری نیست که این سیاره آبی به شدت گرم می‌شود.\n",
      "این مسئله از آنجا حائز اهمیت است که این یخچال‌ها بخش عمده‌ای از ذخایر آب آشامیدنی جهان را تشکیل می‌دهند.\n",
      "همچنین گفته می‌شود گرم‌شدن کرهٔ زمین، در سال ۲۱۰۰ باعث خشکسالی شدید، گرمای سوزان و توفان‌های وحشتناک خواهد شد.\n",
      "آمار سال ۲۰۱۷ نشان می‌دهد که در هر دقیقه مساحتی معادل یک زمین فوتبال از آمازون برای این هدف نابود می‌شود.\n",
      "این پدیده اثر گلخانه‌ای و گازهایی که در آن موثرند، گازهای گلخانه‌ای نامیده می‌شوند.\n",
      "این گروه می‌گویند تصاعد دی‌اکسیدکربن و سایر گازهای گلخانه‌ای کمتر از آن است که تغییرات مشاهده شده را توجیه کند.\n"
     ]
    }
   ],
   "source": [
    "# Gettings best 5 lines             \n",
    "best_sentences = heapq.nlargest(10, sent2score, key=sent2score.get)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
